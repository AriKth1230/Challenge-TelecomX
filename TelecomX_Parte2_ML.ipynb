{"nbformat": 4, "nbformat_minor": 5, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11.8"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Telecom X – Parte 2: Predicción de Cancelación (Churn)\n\nEste notebook está **dividido en 4 secciones** para seguir el flujo solicitado:\n1) **Preparación de datos** (carga CSV tratado, limpieza defensiva, one-hot si hace falta, split y desbalance)  \n2) **Correlación y selección de variables** (matriz de correlación, top variables, mutual information)  \n3) **Modelos predictivos** (Regresión Logística *con* normalización y Random Forest *sin* normalización; métricas y matrices de confusión)  \n4) **Interpretación y conclusiones** (coeficientes LR, importancias RF, permutación opcional, resumen estratégico)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 1) Preparación de datos\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom pandas.api.types import is_object_dtype, is_categorical_dtype\n\n# Ruta del CSV tratado en la Parte 1 (ajústala si usaste otro nombre)\nCANDIDATES = [\"telecomx_ml_ready_numeric.csv\", \"telecomx_ml_ready.csv\", \"telecomx_model_ready.csv\"]\ndf = None\nfor path in CANDIDATES:\n    if os.path.exists(path):\n        df = pd.read_csv(path)\n        print(f\"✔️ Cargado: {path}  shape={df.shape}\")\n        break\nif df is None:\n    raise FileNotFoundError(\"No se encontró un CSV tratado. Asegúrate de tener uno de: \" + \", \".join(CANDIDATES))\n\n# Asegurar objetivo binario 0/1\nif 'abandono' not in df.columns:\n    raise ValueError(\"No se encontró la columna 'abandono' en el CSV.\")\n\nif not set(pd.unique(df['abandono'])).issubset({0,1}):\n    df['abandono'] = (df['abandono'].astype('string').str.strip().str.lower()\n                      .map({'yes':1,'no':0}).astype('int8'))\n\n# Eliminar identificadores únicos si aún existen\nfor c in ['id_cliente','customerID']:\n    if c in df.columns:\n        df = df.drop(columns=[c])\n\n# Si quedan categóricas, aplicar one-hot (drop_first para evitar colinealidad)\ncat_cols = [c for c in df.columns if c!='abandono' and (is_object_dtype(df[c]) or is_categorical_dtype(df[c]))]\nif cat_cols:\n    df = pd.get_dummies(df, columns=cat_cols, drop_first=True, dtype='int8')\n\n# Separar X, y (todo numérico)\ny = df['abandono'].astype('int8')\nX = df.drop(columns=['abandono'])\n\n# Chequeos\nassert not X.isna().any().any(), \"Hay NaNs en X.\"\nassert set(pd.unique(y)).issubset({0,1}), \"La variable objetivo debe ser 0/1.\"\n\nprint(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n\n# Desbalance de clases\ncounts = y.value_counts().sort_index()\nprops  = y.value_counts(normalize=True).sort_index()\nprint(\"\\n=== Distribución de clases ===\")\nprint(f\"Activos (0): {counts.get(0,0)} ({props.get(0,0)*100:.2f}%)\")\nprint(f\"Churn (1):  {counts.get(1,0)} ({props.get(1,0)*100:.2f}%)\")\n\n# Gráfico simple de barras (una figura por gráfico)\nplt.figure()\nplt.bar(['Activos (0)','Churn (1)'], [counts.get(0,0), counts.get(1,0)])\nplt.title('Distribución de clases (conteo)')\nplt.ylabel('Número de clientes')\nfor i, v in enumerate([counts.get(0,0), counts.get(1,0)]):\n    plt.text(i, v*0.98, f'{v}', ha='center', va='top')\nplt.show()\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 2) Correlación y selección de variables\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom sklearn.feature_selection import mutual_info_classif\n\n# Matriz de correlación (solo numéricas)\nnum_cols = X.select_dtypes(include=[np.number]).columns.tolist()\ncorr = pd.concat([X[num_cols], y], axis=1).corr()\n\nprint(\"Top correlaciones con 'abandono':\")\nprint(corr['abandono'].sort_values(ascending=False))\n\n# Heatmap con matplotlib\nfig, ax = plt.subplots(figsize=(10,7))\nim = ax.imshow(corr, vmin=-1, vmax=1, cmap='coolwarm')\nax.set_xticks(range(len(corr.columns)))\nax.set_yticks(range(len(corr.index)))\nax.set_xticklabels(corr.columns, rotation=90)\nax.set_yticklabels(corr.index)\nax.set_title('Matriz de correlación (numéricas + objetivo)')\nfig.colorbar(im, ax=ax, label='Correlación')\nplt.tight_layout()\nplt.show()\n\n# Mutual Information (captura relaciones no lineales)\nmi = mutual_info_classif(X[num_cols], y, random_state=42)\nmi_s = pd.Series(mi, index=num_cols).sort_values(ascending=False)\nprint(\"\\nTop 15 por Mutual Information:\")\ndisplay(mi_s.head(15))\n\n# Gráfico top-15 MI\ntop = mi_s.head(15).sort_values(ascending=True)\nplt.figure(figsize=(8,6))\nplt.barh(top.index, top.values)\nplt.title('Top 15 - Mutual Information con \"abandono\"')\nplt.tight_layout()\nplt.show()\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 3) Modelos predictivos (con y sin normalización)\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, RocCurveDisplay\n\n# Split 70/30 estratificado\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=42, stratify=y\n)\nprint(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n\n# Modelo A: Regresión Logística (requiere normalización)\nlogreg = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('model', LogisticRegression(max_iter=2000, class_weight='balanced', solver='liblinear'))\n])\n\n# Modelo B: Random Forest (no requiere normalización)\nrf = Pipeline(steps=[\n    ('model', RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced'))\n])\n\n# Entrenamiento\nlogreg.fit(X_train, y_train)\nrf.fit(X_train, y_train)\n\ndef evaluar(model, Xtr, ytr, Xte, yte, name=\"modelo\"):\n    y_pred = model.predict(Xte)\n    try:\n        y_proba = model.predict_proba(Xte)[:,1]\n        roc = roc_auc_score(yte, y_proba)\n    except Exception:\n        y_proba, roc = None, np.nan\n\n    acc = accuracy_score(yte, y_pred)\n    pre = precision_score(yte, y_pred, zero_division=0)\n    rec = recall_score(yte, y_pred)\n    f1  = f1_score(yte, y_pred)\n\n    print(f\"\\n=== {name} ===\")\n    print(f\"Accuracy:  {acc:.3f}\")\n    print(f\"Precision: {pre:.3f}\")\n    print(f\"Recall:    {rec:.3f}\")\n    print(f\"F1-score:  {f1:.3f}\")\n    print(f\"ROC AUC:   {roc:.3f}\")\n\n    # Matriz de confusión (una figura)\n    cm = confusion_matrix(yte, y_pred)\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm)\n    ax.set_title(f\"Matriz de confusión — {name}\")\n    ax.set_xlabel(\"Predicción\")\n    ax.set_ylabel(\"Real\")\n    for (i, j), v in np.ndenumerate(cm):\n        ax.text(j, i, str(v), ha='center', va='center')\n    plt.tight_layout()\n    plt.show()\n\n    # Curva ROC si hay proba\n    if y_proba is not None:\n        RocCurveDisplay.from_predictions(yte, y_proba, name=name)\n        plt.title(f\"ROC — {name}\")\n        plt.tight_layout()\n        plt.show()\n\n    print(\"\\nReporte de clasificación (TEST):\")\n    print(classification_report(yte, y_pred, digits=3))\n\nevaluar(logreg, X_train, y_train, X_test, y_test, name=\"Regresión Logística (scaled)\")\nevaluar(rf,     X_train, y_train, X_test, y_test, name=\"Random Forest (no-scale)\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 4) Interpretación y conclusiones\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom sklearn.inspection import permutation_importance\n\nfeat_names = list(X_train.columns)\n\n# 4.1 Coeficientes de Regresión Logística (features ya estandarizadas dentro del pipeline)\nlr_coef = logreg.named_steps['model'].coef_[0]\ncoef_ser = pd.Series(lr_coef, index=feat_names, name='coef_lr')\n\nprint(\"Top 15 coeficientes (valor absoluto) — Regresión Logística:\")\ndisplay(coef_ser.reindex(coef_ser.abs().sort_values(ascending=False).index).head(15))\n\ntop_lr = coef_ser.reindex(coef_ser.abs().sort_values(ascending=True).index).tail(15)\nplt.figure(figsize=(8,6))\nplt.barh(top_lr.index, top_lr.values)\nplt.title(\"Regresión Logística — Top coeficientes (signo importa)\")\nplt.tight_layout()\nplt.show()\n\n# 4.2 Importancias de Random Forest\nrf_imp = rf.named_steps['model'].feature_importances_\nrf_ser = pd.Series(rf_imp, index=feat_names, name='imp_rf')\n\nprint(\"\\nTop 15 importancias — Random Forest:\")\ndisplay(rf_ser.sort_values(ascending=False).head(15))\n\ntop_rf = rf_ser.sort_values(ascending=True).tail(15)\nplt.figure(figsize=(8,6))\nplt.barh(top_rf.index, top_rf.values)\nplt.title(\"Random Forest — Top importancias\")\nplt.tight_layout()\nplt.show()\n\n# 4.3 (Opcional) Importancia por permutación agnóstica al modelo (en TEST)\ntry:\n    r_perm = permutation_importance(logreg, X_test, y_test, n_repeats=10, random_state=42, scoring='f1')\n    perm_ser = pd.Series(r_perm.importances_mean, index=feat_names, name='perm_lr')\n    print(\"\\nTop 10 — Permutation Importance (LR, ΔF1 en test):\")\n    display(perm_ser.sort_values(ascending=False).head(10))\nexcept Exception as e:\n    print(\"Permutation importance (LR) no disponible:\", e)\n\n# 4.4 Mini-conclusiones automáticas (guía para el informe)\ndef resumen_top(series, k=5, desc=\"variable\"):\n    return [f\"{i+1}. {name}\" for i, name in enumerate(series.sort_values(ascending=False).head(k).index)]\n\nresumen = {\n    \"LR_top_coef\": resumen_top(coef_ser.abs(), 5, \"coef_lr\"),\n    \"RF_top_imp\":  resumen_top(rf_ser, 5, \"imp_rf\"),\n}\nprint(\"\\n=== Resumen rápido para tu informe ===\")\nprint(\"LR — variables con mayor |coef|:\", *resumen['LR_top_coef'], sep=\"\\n\")\nprint(\"\\nRF — variables con mayor importancia:\", *resumen['RF_top_imp'], sep=\"\\n\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "### Conclusiones e Insights (para tu informe)\n\n- **Modelos:** se entrenaron **Regresión Logística (con normalización)** y **Random Forest (sin normalización)**.  \n- **Rendimiento:** compara Accuracy/Precision/Recall/F1/ROC AUC (ver celdas anteriores).  \n- **Variables clave:** según *coeficientes* (LR) e *importancias* (RF), destacan las relacionadas con:\n  - **Tipo de contrato** (e.g., *month-to-month*): mayor riesgo de churn.  \n  - **Tenencia** (*meses_en_empresa*): mayor antigüedad reduce churn.  \n  - **Cargos mensuales**: valores altos aumentan el riesgo si no hay valor percibido.  \n  - **Cargos totales**: suele ser factor protector (relacionado a lealtad).  \n  - **Método de pago** (p. ej., *electronic check*): tiende a asociarse con mayor churn.  \n\n**Recomendaciones de retención:**\n1. Incentivar **migración a contratos anual/bianual** para clientes mensuales.  \n2. Enfocar **onboarding y soporte proactivo** en los primeros 6 meses.  \n3. **Revisar planes con cargos altos**; ofrecer bundles/downgrades guiados.  \n4. **Promover pagos automáticos** (tarjeta/transferencia).  \n5. Ofrecer **servicios protectores** (seguridad online/soporte) a segmentos de riesgo.\n\n> Nota: ajusta estas conclusiones con tus *tops* de coeficientes e importancias concretos de tus datos.\n"}]}